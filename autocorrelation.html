<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Autocorrelation</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">An-Pin Huang</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About me</a>
</li>
<li>
  <a href="econometrics.html">Econometrics</a>
</li>
<li>
  <a href="dataScienceML.html">Data Science</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Autocorrelation</h1>

</div>


<p>The purpose of this section is to show that OLS is not an efficient estimator when there is autocorrelation in the error term; instead, the GLS is better.</p>
<p>Assuming <span class="math inline">\(y_t\)</span> can be written as a linear function of <span class="math inline">\(x\)</span> and the error term <span class="math inline">\(\epsilon\)</span> has autocorrelation <span class="math display">\[y_t = 1.2 + 2.2 x_{1,t} + 2.3 x_{2,t} + \epsilon_t \]</span> <span class="math display">\[ \epsilon_t = \rho \epsilon_{t-1} + w_t ,\, where\, w \sim N(0,\sigma^2)\]</span> To simulate <span class="math inline">\(y\)</span> we do:</p>
<pre class="r"><code>library(MASS)
library(matrixStats)
m=50
x &lt;- mvrnorm(n=m,mu=c(0.05,0.08),
             Sigma=matrix(c(0.0004,0.00023,0.00023,0.0006),
                          nrow=2,ncol=2,byrow=TRUE))
## assuming correlation in x
et &lt;- arima.sim(list(order = c(1,0,0),ar=0.8),n=m,rand.gen=rnorm,sd=0.1)
yt &lt;- 1.2 + x %*% c(2.2,2.3)+et</code></pre>
<hr />
<div id="ols" class="section level3">
<h3>OLS</h3>
<p>Then we do regress <span class="math inline">\(y\)</span> on <span class="math inline">\(x\)</span> using OLS:</p>
<pre class="r"><code>regressY &lt;- lm(yt~x)
summary(regressY)</code></pre>
<pre><code>## 
## Call:
## lm(formula = yt ~ x)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.306211 -0.116928  0.006897  0.111135  0.279888 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  1.15381    0.08229  14.022   &lt;2e-16 ***
## x1           3.10485    1.36969   2.267    0.028 *  
## x2           1.70219    1.22030   1.395    0.170    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1519 on 47 degrees of freedom
## Multiple R-squared:  0.2574, Adjusted R-squared:  0.2258 
## F-statistic: 8.147 on 2 and 47 DF,  p-value: 0.0009166</code></pre>
<pre class="r"><code>regressY$coefficients</code></pre>
<pre><code>## (Intercept)          x1          x2 
##    1.153812    3.104848    1.702190</code></pre>
<p>Test the autocorrelation of residuals</p>
<pre class="r"><code>resi &lt;- regressY$residuals
pacf(resi)</code></pre>
<p><img src="autocorrelation_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>ar.ols(resi)</code></pre>
<pre><code>## 
## Call:
## ar.ols(x = resi)
## 
## Coefficients:
##       1        2        3  
##  0.7149   0.4494  -0.3729  
## 
## Intercept: -0.001978 (0.01178) 
## 
## Order selected 3  sigma^2 estimated as  0.00648</code></pre>
<hr />
</div>
<div id="gls" class="section level3">
<h3>GLS</h3>
<p>GLS with AR(1) residuals is actually OLS on the below equation:</p>
<p><span class="math display">\[y_t - \rho y_{t-1} = \alpha (1-\rho) + \beta_1(x_{1,t} - \rho  x_{1,t-1}) + \beta_2 (x_{2,t} - \rho  x_{2,t-1}) + w\]</span></p>
<pre class="r"><code>## regress on resi hat
regressE &lt;- lm(resi[2:length(resi)]~resi[1:(length(resi)-1)]-1)
rho &lt;- regressE$coefficients[1]
## GLS
## yt - rho * yt_1 = alpha * (1-rho) + beta1*(x1_t - rho * x1_t-1) + beta * 
## (x2_t - rho * x2_t-1)
yt2 &lt;- yt[2:length(yt)]
xt2 &lt;- x[2:nrow(x),]
xprime &lt;- (xt2- c(rho,rho) * x[1:(nrow(x)-1),])
regressY_GLS &lt;- lm( (yt2-rho*yt[1:(length(yt)-1)]) ~ xprime)
summary(regressY_GLS)</code></pre>
<pre><code>## 
## Call:
## lm(formula = (yt2 - rho * yt[1:(length(yt) - 1)]) ~ xprime)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.228986 -0.058280 -0.002183  0.067476  0.191641 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.21848    0.01416  15.428  &lt; 2e-16 ***
## xprime1      2.18329    0.62010   3.521 0.000983 ***
## xprime2      2.43274    0.53077   4.583  3.5e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.08781 on 46 degrees of freedom
## Multiple R-squared:  0.6333, Adjusted R-squared:  0.6174 
## F-statistic: 39.73 on 2 and 46 DF,  p-value: 9.502e-11</code></pre>
<pre class="r"><code>alpha &lt;- regressY_GLS$coefficients[1]/(1-rho)
alpha</code></pre>
<pre><code>## (Intercept) 
##    1.129601</code></pre>
<p>See if the residuals of GLS has autocorrelation:</p>
<pre class="r"><code>resiGLS &lt;- regressY_GLS$residuals
pacf(resiGLS)</code></pre>
<p><img src="autocorrelation_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<hr />
</div>
<div id="run-n-times-to-observe-the-sampling-distribution-of-ols-and-gls-estimators" class="section level3">
<h3>Run n times to observe the sampling distribution of OLS and GLS estimators</h3>
<p>We redo the above steps for n times:</p>
<pre class="r"><code>n=2000
OLS_coefs &lt;- matrix(nrow=n,ncol=3)
GLS_coefs &lt;- matrix(nrow=n,ncol=3)
for(i in 1:n) {
  x &lt;- mvrnorm(n=m,mu=c(0.05,0.08),
               Sigma=matrix(c(0.0004,0.00023,0.00023,0.0006),
                            nrow=2,ncol=2,byrow=TRUE))
  ## assuming autocorrelation in x
  et &lt;- arima.sim(list(order = c(1,0,0),ar=0.8),n=m,rand.gen=rnorm,sd=0.1)
  yt &lt;- 1.2 + x %*% c(2.2,2.3)+et
  
  regressY &lt;- lm(yt~x)
  #summary(regressY)
  OLS_coefs[i,] &lt;- regressY$coefficients
  
  ## GLS
  resi &lt;- regressY$residuals
  regressE &lt;- lm(resi[2:length(resi)]~resi[1:(length(resi)-1)])
  rho &lt;- regressE$coefficients[2]
  ## GLS
  ## yt - rho * yt_1 = alpha * (1-rho) + beta1*(x1_t - rho * x1_t-1) + beta * 
  ## (x2_t - rho * x2_t-1)
  # yt2 &lt;- yt[2:length(yt)]
  # xt2 &lt;- x[2:nrow(x),]
  # xprime &lt;- (xt2- c(rho,rho) * x[1:(nrow(x)-1),])
  # regressY_GLS &lt;- lm( (yt2-rho*yt[1:(length(yt)-1)]) ~ xprime)
  # alpha &lt;- regressY_GLS$coefficients[1]/(1-rho)
  # GLS_coefs[i,1] &lt;- alpha
  # GLS_coefs[i,2:3] &lt;- regressY_GLS$coefficients[2:3]
  GLS_coefs[i,] &lt;- CochraneOrcuttIteration(yt,x,0.001)
}
colMeans(OLS_coefs)</code></pre>
<pre><code>## [1] 1.198000 2.218512 2.282796</code></pre>
<pre class="r"><code>colMeans(GLS_coefs)</code></pre>
<pre><code>## [1] 1.197466 2.218380 2.296711</code></pre>
<p><strong>The variance of the sampling distribution of GLS is much smaller than that of the OLS, and is therefore more effieicnt.</strong></p>
<pre class="r"><code>colVars(OLS_coefs)</code></pre>
<pre><code>## [1] 0.01071182 1.65258858 1.09495078</code></pre>
<pre class="r"><code>colVars(GLS_coefs)</code></pre>
<pre><code>## [1] 0.006902348 0.452834704 0.290013761</code></pre>
<pre class="r"><code>hist(OLS_coefs[,2],breaks=20,xlim=c(-5,10),ylim=c(0,600))</code></pre>
<p><img src="autocorrelation_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre class="r"><code>hist(GLS_coefs[,2],breaks=20,xlim=c(-5,10),ylim=c(0,600))</code></pre>
<p><img src="autocorrelation_files/figure-html/unnamed-chunk-8-2.png" width="672" /></p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
