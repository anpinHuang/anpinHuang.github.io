<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Logistic Regression</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">An-Pin Huang</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About me</a>
</li>
<li>
  <a href="econometrics.html">Econometrics</a>
</li>
<li>
  <a href="dataScienceML.html">Data Science</a>
</li>
<li>
  <a href="Finance.html">Finance</a>
</li>
<li>
  <a href="Programming.html">Programming</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Logistic Regression</h1>

</div>


<p>To solve a classification problem, <span class="math inline">\(y_i\)</span> is either <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span>, we want to estimate the probability of <span class="math inline">\(y_i=1\)</span> by a set of explanatory variable <span class="math inline">\(X\)</span>, denoted as <span class="math inline">\(p(x)\)</span>. However, we cannot simply model the probability by the linear regression model as <span class="math inline">\(p(x) = \beta_0 + x \beta\)</span> since the probability is bound between [0,1] whereas the linear function of the explanatory variables is unbounded.</p>
<p>By transforming the probability to log odds ratio, the target variable becomes unbounded and can be expressed as iinear function of the explanatory variables: <span class="math display">\[log\frac{p(x)}{1-p(x)} = \beta_0 + x\beta\]</span> Now the equation looks like an OLS. However, we cannot model the log odds ratio using OLS because of Jenson’s Inequility (<span class="math inline">\(E[f(X)] \neq f(E[X])\)</span>). In this case, we want to know <span class="math inline">\(E[p(x)]\)</span>, but by using OLS on log odds ratio, we can only get <span class="math inline">\(E[log \frac{p(x)}{1-p(x)}]\)</span>. When transforming the data to log(odds), the target variable becomes positive and negative infinity, and therefore the residuals cannot be calculated.</p>
<p>Instead, we want to estimate the <span class="math inline">\(p(x)\)</span> directly. It can be done by using gradient descent or maximum likehood.</p>
The probability can be expressed as the log(odds): $$
<span class="math display">\[\begin{aligned}
log(\frac{p}{1-p}) &amp;=  log(odds) \\
\frac{p}{1-p} &amp;= e^{log(odds)} \\
p &amp;= (1-p)e^{log(odds)} \\
p &amp;= e^{log(odds)}-pe^{log(odds)} \\
p+pe^{log(odds)} &amp;=e^{log(odds)}\\
p &amp;= \frac{e^{log(odds)}}{1+e^{log(odds)}}

\end{aligned}\]</span>
<p>$$</p>
<hr />
<p>To estimate the probability directly, we define the probability estimator as:</p>
<p><span class="math display">\[\hat p  = h_{\theta}(x) = \sigma(\beta_0+x\beta)\]</span></p>
<p>where <span class="math inline">\(\sigma\)</span> is the sigmoid function <span class="math inline">\(\sigma(t) = \frac{1}{1+e^{-t}}\)</span></p>
<pre class="r"><code>t &lt;- seq(-10,10, length=40)
sigmoid_t &lt;- 1/(1+exp(-t))
plot(t, sigmoid_t, col=&quot;blue&quot;, lwd=2,type=&#39;l&#39;)</code></pre>
<p><img src="LogisticRegression_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p><span class="math inline">\(\hat y = 0 \,\, if \,\,\hat p&lt;0.5\)</span> and <span class="math inline">\(\hat y = 1 \,\, if \,\,\hat p\geq0.5\)</span></p>
<p>or more explicitly,</p>
<p><span class="math display">\[\hat p  = \frac{1}{1+e^{-\beta_0+x\beta}}\]</span></p>
<div style="background-color:white;color:blue;matrixOperation:20px;">
<h3 id="cost-function">Cost Function</h3>
</div>
<p>singel training instance cost function: <span class="math display">\[
c(\beta_0, \beta) =
  \begin{cases}
    -log(\hat p)       &amp; \quad \text{if } y=1\\
    -log(1-\hat p)  &amp; \quad \text{if } y=0
  \end{cases}
\]</span> logistic regression cost function: <span class="math display">\[l(\beta_0, \beta) = -\frac{1}{n}\sum_{i=1}^{n}[y_ilog(\hat p)+(1-y_i)log(1-\hat p)]\]</span> It’s similar to the log likelihood function, where we can define the likelihood function as:</p>
<p><span class="math display">\[ L(\beta_0, \beta) = \prod_{i=1}^{n}p(x_i)^{y_i}(1-p(x_i)^{1-y_i})\]</span> then <strong>log-likelihood function</strong> is then:</p>
<p><span class="math display">\[l(\beta_0, \beta) = \sum_{i=1}^{n}y_i(log(p(x_i)))+(1-y_i)log(1-p(x_i)) \]</span></p>
<p>The estimation can either done by minimize the cost function or maximize the log-likelihood function</p>
<p>logistic cost function partial derivatives: <span class="math display">\[\frac{\partial}{\partial \theta_j}l(\theta) = \frac{1}{n}\sum_{i=1}^{n}(\sigma(\theta^T x^{(i)}-y^{(i)}))x_j^{(i)}\]</span> The logistic regression does not have analytical solution, it must be solved numerically.</p>
<div style="background-color:white;color:blue;matrixOperation:20px;">
<h3 id="goodness-of-fit">Goodness of Fit</h3>
</div>
<p>We discuss one of the ways to measure the goodness of fit.</p>
<p><strong>McFadden’s psuedo <span class="math inline">\(R^2\)</span></strong></p>
<p>Recall that the <span class="math inline">\(R^2=\frac{SS(mean)-SS(fit)}{SS(mean)}\)</span> in linear regression where <span class="math inline">\(SS\)</span> means the sum of residual’s square <span class="math inline">\(SS(mean)\)</span> is the sum of residual’s square where the prediction is just the average of the sample target variable. However, we can’t use the residual.</p>
<p>We use <span class="math inline">\(LL(fit)\)</span> for the log-likelihood of the fitted line, and use it as a substitute for <span class="math inline">\(SS(fit)\)</span>. Now we need to substitution for <span class="math inline">\(SS(mean)\)</span>. For benchmarking purpose, we have to find substitution for <span class="math inline">\(SS(mean)\)</span>. We can use the log-likelihood of the estimation with no explanatory variable. This would be the log-likelihood with the estimate of probability <span class="math inline">\(\hat{p}\)</span> equals to the sum of <span class="math inline">\(y\)</span> divided by number of observations. We denote this as <span class="math inline">\(LL(0)\)</span>. Now we have the McFadden’s psuedo <span class="math display">\[R^2 = \frac{LL(0)-LL(fit)}{LL(0)}\]</span></p>
<p>We use the null and saturated model to calculate the proposed model’s R square and p-value * Null model: an oversimplified model * Saturated model: an over-complicated model</p>
<p>Review R squuare for linear regression: <span class="math display">\[R^2 = \frac{SS(Null Model)-SS(Proposed Model)}{SS(Null Model)}\]</span> Null Model here is the average of the target variable.</p>
<p>Now for log-likelihood based R square:</p>
<p><span class="math display">\[R^2 = \frac{LL(Null Model)-LL(Proposed Model)}{LL(Null Model)-LL(SaturatedModel)}\]</span></p>
<p><strong>The inclusion of saturated model ensures that the R square is between 0 and 1!</strong></p>
<ul>
<li><strong>Residual deviance: </strong> <span class="math inline">\(2 \cdot (LL(SaturatedModel)-LL(ProposedModel))\)</span> follows Chi-square distribution. For this to work, the proposed model has to be a simplier version of the saturated model</li>
<li><strong>Null deviance: </strong> <span class="math inline">\(2 \cdot (LL(SaturatedModel)-LL(NullModel))\)</span></li>
<li><span class="math inline">\(Null Deviance - Residual Deviance\)</span> is a Chi-square value with degree of freedom equal to the difference in the number of parameters for the proposed Model and the Null Model</li>
<li><strong>Deviance residuals: </strong> <span class="math inline">\(\sum_i^N \sqrt{2 \cdot LL(SaturatedModel)_i - LL(ProposedModel)_i}\)</span>Analogous to the residuals of OLS.</li>
</ul>
<p>Logistic regression is a special case where we can ingnore the saturated model when calculating the R swuare as the <span class="math inline">\(LL(SaturatedModel)=0\)</span>.</p>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
