---
title: "Credit Default Prediction"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: true
bibliography: references.bib
link-citations: yes
---

###  1. Overview

The goal of this page is to explore how different machine algorithms work for predicting the default probability of a credit position (loan).

The datasets that are being used are

* The information of the loan application, including the borrower's income, the credit amount, the annuity (yearly payment), income source and etc.
* The information from the credit bureau regarding the loan applicants, e.g. credit inquiry, days past due information.
* The credit card information that the borrower's has with the lender.

```{r load-data, echo=FALSE, eval = FALSE}
tran <- read.csv("/Users/smartboyben/documents/Data/home-credit-default-risk/application_train.csv")
bureau <- read.csv("/Users/smartboyben/documents/Data/home-credit-default-risk/bureau.csv") 
card <- read.csv("/Users/smartboyben/documents/Data/home-credit-default-risk/credit_card_balance.csv")  

train_size <- round(nrow(tran)/3*2)
tran_train <- sample(1:nrow(tran), train_size, replace=FALSE)
tran_test <- setdiff(c(1:nrow(tran)), tran_train)
```



### 2. Feature engineering

* inverse of loan to value ratio (LTV) 
* inverse of loan to income ratio
* income to annuity ratio

```{r treat-data}
# 365243 should be considered as NA
tran[which(tran[,'DAYS_EMPLOYED']==365243),'DAYS_EMPLOYED'] <- NA
tran[which(tran[,'DAYS_BIRTH']==365243),'DAYS_BIRTH'] <- NA
```

```{r}
tran$VTL <- tran$AMT_GOODS_PRICE/tran$AMT_CREDIT
tran$ITL <- tran$AMT_INCOME_TOTAL/tran$AMT_CREDIT
tran$ITA <- tran$AMT_INCOME_TOTAL/tran$AMT_ANNUITY
```

Derive features from credit bureau data

* number of credit applications in the past 12 months
* number of credit applications in the past 24 months
* number of credit applications
* total outstanding credit
* active annuity from bureau (later use to calculate other ratios)
* utilization rate (credit/credit_limit)
```{r bureau-data}
library(sqldf)
 
bureau_groupbyID <- sqldf("
select SK_ID_CURR
, sum(case when DAYS_CREDIT > -365 then 1 else 0 end) as b_CreditInquiry12M
, sum(case when DAYS_CREDIT > -730 then 1 else 0 end) as b_CreditInquiry24M
, count(*) as b_CreditInquiryAll
, sum(case when CREDIT_ACTIVE='Active' then AMT_CREDIT_SUM else 0 end) as b_AMT_CREDIT_SUM
, sum(case when CREDIT_ACTIVE='Active' then AMT_CREDIT_SUM_DEBT else 0 end) as b_AMT_CREDIT_SUM_DEBT
, sum(case when CREDIT_ACTIVE='Active' then AMT_ANNUITY else 0 end) as b_AMT_ANNUITY
, sum(case when CREDIT_ACTIVE='Active' then AMT_CREDIT_SUM_LIMIT else 0 end) as b_AMT_CREDIT_SUM_LIMIT
from bureau 
group by 1")

```



Derive features from credit card balance

* average of the balance
* standard of the balance
* average of the limit
* standard deviation of the limit
* average of the utilization rate
* standard deviation of the utilication rate
```{r credit-card-data}
library(sqldf)
## combined card information if 1 customer has more than 1 credit card
CardPerPerson <- sqldf("
select SK_ID_CURR, MONTHS_BALANCE
, sum(AMT_BALANCE) as AMT_BALANCE
, sum(AMT_CREDIT_LIMIT_ACTUAL) as AMT_CREDIT_LIMIT_ACTUAL
, max(SK_DPD) as SK_DPD
from card
group by 1,2")

CardFeatures <- sqldf("
select SK_ID_CURR
, avg(AMT_BALANCE) as c_AMT_BALANCE_mean
, stdev(AMT_BALANCE) as c_AMT_BALANCE_sd
, avg(AMT_CREDIT_LIMIT_ACTUAL) as c_AMT_LIMIT_mean
, stdev(AMT_CREDIT_LIMIT_ACTUAL) as c_AMT_LIMIT_sd
, avg(AMT_BALANCE/AMT_CREDIT_LIMIT_ACTUAL) c_utilization_mean
, stdev(AMT_BALANCE/AMT_CREDIT_LIMIT_ACTUAL) c_utilization_sd
, max(SK_DPD) as c_SK_DPD_max
from CardPerPerson
group by 1
")
```


Combine the features of credit bureau & credit card to the applicatino dataset
```{r combine-RDS}
tran_ext <- sqldf("
select 
a.*
, b.b_CreditInquiry12M
, b.b_CreditInquiry24M
, b.b_CreditInquiryAll
, b.b_AMT_CREDIT_SUM
, b.b_AMT_CREDIT_SUM_DEBT
, b.b_AMT_ANNUITY
, b.b_AMT_CREDIT_SUM_LIMIT
, c.c_AMT_BALANCE_mean
, c.c_AMT_BALANCE_sd
, c.c_AMT_LIMIT_mean
, c.c_AMT_LIMIT_sd
, c.c_utilization_mean
, c.c_utilization_sd
, c.c_SK_DPD_max
from tran a
left join bureau_groupbyID b
on a.SK_ID_CURR=b.SK_ID_CURR
left join CardFeatures c
on a.SK_ID_CURR=c.SK_ID_CURR")
  
```

Derive additional features
```{r more-features}
tran_ext$CreditIncreaseMult <- tran_ext$b_AMT_CREDIT_SUM/tran_ext$AMT_CREDIT
tran_ext$PaymentStress <- (tran_ext$b_AMT_ANNUITY + tran_ext$AMT_ANNUITY)/tran_ext$AMT_INCOME_TOTAL
tran_ext$InquiryRatio12M <- tran_ext$b_CreditInquiry12M/tran_ext$b_CreditInquiryAll
tran_ext$DaysEmployedRatio <- tran_ext$DAYS_EMPLOYED/tran_ext$DAYS_BIRTH
tran_ext$IncomeToDaysEmployed <- tran_ext$AMT_INCOME_TOTAL/tran_ext$DAYS_EMPLOYED
tran_ext$IncomePerPerson <- tran_ext$AMT_INCOME_TOTAL/tran_ext$CNT_FAM_MEMBERS
```

Exclude building variables due to large amount of missing
```{r}
exclude_list <- c("YEARS_BUILD_AVG"
,"COMMONAREA_AVG","ELEVATORS_AVG","ENTRANCES_AVG","FLOORSMAX_AVG","FLOORSMIN_AVG","LANDAREA_AVG","LIVINGAPARTMENTS_AVG","LIVINGAREA_AVG","NONLIVINGAPARTMENTS_AVG","NONLIVINGAREA_AVG","APARTMENTS_MODE","BASEMENTAREA_MODE","YEARS_BEGINEXPLUATATION_MODE","YEARS_BUILD_MODE","COMMONAREA_MODE","ELEVATORS_MODE","ENTRANCES_MODE","FLOORSMAX_MODE","FLOORSMIN_MODE","LANDAREA_MODE","LIVINGAPARTMENTS_MODE","LIVINGAREA_MODE","NONLIVINGAPARTMENTS_MODE","NONLIVINGAREA_MODE","APARTMENTS_MEDI","BASEMENTAREA_MEDI","YEARS_BEGINEXPLUATATION_MEDI","COMMONAREA_MEDI","ELEVATORS_MEDI","ENTRANCES_MEDI","FLOORSMAX_MEDI","FLOORSMIN_MEDI","LANDAREA_MEDI","LIVINGAPARTMENTS_MEDI","LIVINGAREA_MEDI","NONLIVINGAPARTMENTS_MEDI","NONLIVINGAREA_MEDI","FONDKAPREMONT_MODE","TOTALAREA_MODE","WALLSMATERIAL_MODE")
tran_ext <- tran_ext[,setdiff(colnames(tran_ext),exclude_list)]
```


###  3. Information value
```{r IV}
library(Information)
library(gridExtra)

### Ranking variables using penalized IV  
IV <- create_infotables(data=tran_ext[tran_train,],y="TARGET")
#head(IV$Summary, 50)
grid.table(head(IV$Summary, 50), rows=NULL)
```


```{r, echo=FALSE,eval = FALSE}
library(Information)
library(gridExtra)
### Ranking variables using penalized IV  
IV$Tables$EXT_SOURCE_1
IV$Tables$EXT_SOURCE_2
IV$Tables$EXT_SOURCE_3

IV$Tables$DAYS_EMPLOYED
IV$Tables$DAYS_BIRTH
IV$Tables$OCCUPATION_TYPE
IV$Tables$NAME_INCOME_TYPE
IV$Tables$NAME_INCOME_TYPE
#grid.table(IV$Tables$EXT_SOURCE_1, rows=NULL)
```


###  Correlation analysis of X

To avoid including strongly correlated variables in the explanatory variable set, the following correlation analysis is performed. 

```{r correlation}
## correlation analysis of X's
cor(tran_ext[tran_train,c('EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3')], use="pairwise.complete.obs",method="spearman")
cor(tran_ext[tran_train,c('DAYS_BIRTH','DAYS_EMPLOYED','IncomeToDaysEmployed','DaysEmployedRatio')],method="spearman",use='pairwise.complete.obs')
cor(tran_ext[tran_train,c('InquiryRatio12M','b_CreditInquiry12M','b_CreditInquiry24M')],method="spearman",use='pairwise.complete.obs')

cor(tran_ext[tran_train,c('b_AMT_CREDIT_SUM_DEBT','CreditIncreaseMult','AMT_CREDIT','PaymentStress','b_AMT_ANNUITY')],method="spearman",use='pairwise.complete.obs')

cor(tran_ext[tran_train,c('c_utilization_mean','c_AMT_BALANCE_mean')],method="spearman",use='pairwise.complete.obs')
```


### 4. Strategy-driven vars

Variables that are related to the loan amount (credit) or the payment (strategy) can be strategy-driven and thus are not ideal variables for predicting the default risk. For example, if the company's lending costs or operational costs have decreased and therefore can take on more risk and increase the credit it is extending. This change does not directly provide the casual effect on the default risk of the client. 


### 5. Logistic regression 

The explanatory variables are transformed to WOE before serving as the independent variables for the logistic regression. Highly correlated variables are excluded from the previous step.

```{r WOE,eval = FALSE}
library(scorecard)
vars_logistic <- c('EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3','InquiryRatio12M','DAYS_BIRTH','DAYS_EMPLOYED','OCCUPATION_TYPE','VTL','ORGANIZATION_TYPE','NAME_INCOME_TYPE','AMT_GOODS_PRICE','NAME_EDUCATION_TYPE','c_utilization_mean','b_CreditInquiry24M','REGION_RATING_CLIENT_W_CITY','b_AMT_CREDIT_SUM_DEBT','DAYS_LAST_PHONE_CHANGE','PaymentStress','c_utilization_sd','HOUSETYPE_MODE','NAME_FAMILY_STATUS','b_AMT_ANNUITY','OWN_CAR_AGE','REG_CITY_NOT_LIVE_CITY','DAYS_REGISTRATION','CODE_GENDER','FLAG_EMP_PHONE','FLAG_DOCUMENT_3')

## the binning & woe is created using training set and will later be applied to testing set to create clean out-of-sample testing
woes <- woebin(dt = tran_ext[tran_train,c('TARGET',vars_logistic)], y='TARGET')

var_woes <- woebin_ply(dt = tran_ext[tran_train,c('TARGET',vars_logistic)], bins = woes, to = "woe", no_cores = 2, print_step = 0L)
```

```{r}
model <- glm(TARGET ~.,family=binomial(link='logit'),data=var_woes)
summary(model)
```


```{r}
library(pROC)
predicted_logistic <- predict(model, var_woes, type="response")
auc(tran_ext[tran_train,"TARGET"], predicted_logistic)

var_woes_test <- woebin_ply(dt = tran_ext[tran_test,c('TARGET',vars_logistic)], bins = woes, to = "woe", no_cores = 2, print_step = 0L)
predicted_logistic_test <- predict(model, var_woes_test, type="response")
auc(tran_ext[tran_test,"TARGET"], predicted_logistic_test)
```


### 6. Decision tree

```{r tree,eval = FALSE}
library(rpart)
mytree <- rpart(TARGET~., data = tran[tran_train,], method = "class", cp=0.0001, maxdepth = 9)
```

```{r}
library(rpart)
predicted_tree_train <- predict(mytree, tran[tran_train,], type ="prob")
auc(tran[tran_train,"TARGET"], predicted_tree_train[,'1'])
predicted_tree_test <- predict(mytree, tran[tran_test,], type ="prob")
auc(tran[tran_test,"TARGET"], predicted_tree_test[,'1'])                                
                                
```


### 7. Gradient boosting

```{r,eval = FALSE}
library(gbm)
gbm_tree <- gbm.fit <- gbm(
  formula = TARGET ~ .,
  distribution = "bernoulli",
  data = tran_ext[tran_train,],
  n.minobsinnode=30,
  n.trees = 1000,
  interaction.depth = 2,
  shrinkage = 0.005, # learning rate
  n.cores = NULL, # will use all cores by default
  verbose = TRUE
  )                                
                                
```

```{r}
predicted_gbm_train <- predict(gbm_tree, n.trees = gbm_tree$n.trees, tran_ext[tran_train,], type="response")                             
auc(tran_ext[tran_train,"TARGET"], predicted_gbm_train)   
predicted_gbm_test <- predict(gbm_tree, n.trees = gbm_tree$n.trees, tran_ext[tran_test,], type="response")  
auc(tran_ext[tran_test,"TARGET"], predicted_gbm_test)  
```



